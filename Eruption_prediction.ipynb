{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623502b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle\n",
    "#!pip install pandas\n",
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8347bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fdd7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(\"./predict-volcanic-eruptions-ingv-oe\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(\"./output\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db27713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = \"rubbenliu\"\n",
    "os.environ['KAGGLE_KEY'] = \"4193b9c51b3a2626398f17079aaeab3f\"\n",
    "\n",
    "#!kaggle competitions download -c predict-volcanic-eruptions-ingv-oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a3279a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pathlib.Path(\"./predict-volcanic-eruptions-ingv-oe/sample_submission.csv\").exists():\n",
    "    zip_path = \"/home/ec2-user/SageMaker/predict-volcanic-eruptions-ingv-oe.zip\"\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "        f.extractall(\"./predict-volcanic-eruptions-ingv-oe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e175a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(signal, ts, sensor_id):\n",
    "    X = pd.DataFrame()\n",
    "    f = np.fft.fft(signal)\n",
    "    f_real = np.real(f)\n",
    "    X.loc[ts, f'{sensor_id}_sum']       = signal.sum()\n",
    "    X.loc[ts, f'{sensor_id}_mean']      = signal.mean()\n",
    "    X.loc[ts, f'{sensor_id}_std']       = signal.std()\n",
    "    X.loc[ts, f'{sensor_id}_var']       = signal.var() \n",
    "    X.loc[ts, f'{sensor_id}_max']       = signal.max()\n",
    "    X.loc[ts, f'{sensor_id}_min']       = signal.min()\n",
    "    X.loc[ts, f'{sensor_id}_skew']      = signal.skew()\n",
    "    #X.loc[ts, f'{sensor_id}_mad']       = signal.mad()\n",
    "    X.loc[ts, f'{sensor_id}_kurtosis']  = signal.kurtosis()\n",
    "    X.loc[ts, f'{sensor_id}_quantile99']= np.quantile(signal, 0.99)\n",
    "    X.loc[ts, f'{sensor_id}_quantile95']= np.quantile(signal, 0.95)\n",
    "    X.loc[ts, f'{sensor_id}_quantile85']= np.quantile(signal, 0.85)\n",
    "    X.loc[ts, f'{sensor_id}_quantile75']= np.quantile(signal, 0.75)\n",
    "    X.loc[ts, f'{sensor_id}_quantile55']= np.quantile(signal, 0.55)\n",
    "    X.loc[ts, f'{sensor_id}_quantile45']= np.quantile(signal, 0.45) \n",
    "    X.loc[ts, f'{sensor_id}_quantile25']= np.quantile(signal, 0.25) \n",
    "    X.loc[ts, f'{sensor_id}_quantile15']= np.quantile(signal, 0.15) \n",
    "    X.loc[ts, f'{sensor_id}_quantile05']= np.quantile(signal, 0.05)\n",
    "    X.loc[ts, f'{sensor_id}_quantile01']= np.quantile(signal, 0.01)\n",
    "    X.loc[ts, f'{sensor_id}_fft_real_mean']= f_real.mean()\n",
    "    X.loc[ts, f'{sensor_id}_fft_real_std'] = f_real.std()\n",
    "    X.loc[ts, f'{sensor_id}_fft_real_max'] = f_real.max()\n",
    "    X.loc[ts, f'{sensor_id}_fft_real_min'] = f_real.min()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9191b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./predict-volcanic-eruptions-ingv-oe/train.csv\")\n",
    "sample_submission = pd.read_csv(\"./predict-volcanic-eruptions-ingv-oe/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7fcaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frags = glob.glob(\"./predict-volcanic-eruptions-ingv-oe/test/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aaa630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "sensors = set()\n",
    "observations = set()\n",
    "nan_columns = list()\n",
    "missed_groups = list()\n",
    "for_test_df = list()\n",
    "\n",
    "j=0\n",
    "\n",
    "for item in test_frags:\n",
    "    name = int(item.replace('\\\\','/').split('.')[-2].split('/')[-1])\n",
    "    at_least_one_missed = 0\n",
    "    frag = pd.read_csv(item)\n",
    "    missed_group = list()\n",
    "    missed_percents = list()\n",
    "    for col in frag.columns:\n",
    "        missed_percents.append(frag[col].isnull().sum() / len(frag))\n",
    "        if pd.isnull(frag[col]).all() == True:\n",
    "            at_least_one_missed = 1\n",
    "            nan_columns.append(col)\n",
    "            missed_group.append(col)\n",
    "    if len(missed_group) > 0:\n",
    "        missed_groups.append(missed_group)\n",
    "    sensors.add(len(frag.columns))\n",
    "    observations.add(len(frag))\n",
    "    for_test_df.append([name, at_least_one_missed] + missed_percents)\n",
    "    \n",
    "    if j%500 == 0:\n",
    "        print(j)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_test_df = pd.DataFrame(\n",
    "    for_test_df, \n",
    "    columns=[\n",
    "        'segment_id', 'has_missed_sensors', 'missed_percent_sensor1', 'missed_percent_sensor2', 'missed_percent_sensor3', \n",
    "        'missed_percent_sensor4', 'missed_percent_sensor5', 'missed_percent_sensor6', 'missed_percent_sensor7', \n",
    "        'missed_percent_sensor8', 'missed_percent_sensor9', 'missed_percent_sensor10'\n",
    "    ]\n",
    ")\n",
    "\n",
    "for_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676275a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list()\n",
    "j=0\n",
    "for seg in train.segment_id:\n",
    "    signals = pd.read_csv(f'./predict-volcanic-eruptions-ingv-oe/train/{seg}.csv')\n",
    "    train_row = []\n",
    "    if j%500 == 0:\n",
    "        print(j)\n",
    "    for i in range(0, 10):\n",
    "        sensor_id = f'sensor_{i+1}'\n",
    "        train_row.append(build_features(signals[sensor_id].fillna(0), seg, sensor_id))\n",
    "    train_row = pd.concat(train_row, axis=1)\n",
    "    train_set.append(train_row)\n",
    "    j+=1\n",
    "\n",
    "train_set = pd.concat(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9873494",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.reset_index()\n",
    "train_set = train_set.rename(columns={'index': 'segment_id'})\n",
    "train_set = pd.merge(train_set, train, on='segment_id')\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = list()\n",
    "for col in train_set.columns:\n",
    "    if col == 'segment_id':\n",
    "        continue\n",
    "    if abs(train_set[col].corr(train_set['time_to_eruption'])) < 0.01:\n",
    "        drop_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f034f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_to_drop_cols = list()\n",
    "\n",
    "for col1 in train_set.columns:\n",
    "    for col2 in train_set.columns:\n",
    "        if col1 == col2:\n",
    "            continue\n",
    "        if col1 == 'segment_id' or col2 == 'segment_id': \n",
    "            continue\n",
    "        if col1 == 'time_to_eruption' or col2 == 'time_to_eruption':\n",
    "            continue\n",
    "        if abs(train_set[col1].corr(train_set[col2])) > 0.98:\n",
    "            if col2 not in drop_cols and col1 not in not_to_drop_cols:\n",
    "                drop_cols.append(col2)\n",
    "                not_to_drop_cols.append(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_set.drop(['segment_id', 'time_to_eruption'], axis=1)\n",
    "y = train_set['time_to_eruption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd4393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./output/preprocessed_train.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_y = y.copy()\n",
    "reduced_train = train.copy()\n",
    "reduced_train = reduced_train.drop(drop_cols, axis=1)\n",
    "reduced_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, y, y_val = train_test_split(train, y, random_state=42, test_size=0.2, shuffle=True)\n",
    "reduced_train, reduced_val, reduced_y, reduced_y_val = train_test_split(reduced_train, reduced_y, random_state=42, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6348173",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor(\n",
    "    random_state=42, \n",
    "    max_depth=7, \n",
    "    n_estimators=250, \n",
    "    learning_rate=0.12\n",
    ")\n",
    "\n",
    "lgb.fit(train, y)\n",
    "preds = lgb.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mse(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fcaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simple LGB model rmse: ', rmse(y_val, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585ed38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = list()\n",
    "j=0\n",
    "for seg in sample_submission.segment_id:\n",
    "    signals = pd.read_csv(f'./predict-volcanic-eruptions-ingv-oe/test/{seg}.csv')\n",
    "    test_row = []\n",
    "    if j%500 == 0:\n",
    "        print(j)\n",
    "    for i in range(0, 10):\n",
    "        sensor_id = f'sensor_{i+1}'\n",
    "        test_row.append(build_features(signals[sensor_id].fillna(0), seg, sensor_id))\n",
    "    test_row = pd.concat(test_row, axis=1)\n",
    "    test_set.append(test_row)\n",
    "    j+=1\n",
    "test_set = pd.concat(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ae041",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.reset_index()\n",
    "test_set = test_set.rename(columns={'index': 'segment_id'})\n",
    "test_set = pd.merge(test_set, for_test_df, how='left', on='segment_id')\n",
    "test = test_set.drop(['segment_id'], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8562d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_test = test.copy()\n",
    "reduced_test = reduced_test.drop(drop_cols, axis=1)\n",
    "reduced_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./output/preprocessed_test.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = lgb.predict(test)\n",
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.booster_.save_model('lgbr_base.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22a70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "# train_model_id, train_model_version, train_scope = \"lightgbm-classification-model\", \"*\", \"training\"\n",
    "# training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# # Retrieve the docker image\n",
    "# train_image_uri = image_uris.retrieve(\n",
    "#     region=None,\n",
    "#     framework=None,\n",
    "#     model_id=train_model_id,\n",
    "#     model_version=train_model_version,\n",
    "#     image_scope=train_scope,\n",
    "#     instance_type=training_instance_type\n",
    "# )\n",
    "\n",
    "# # Retrieve the training script\n",
    "# train_source_uri = script_uris.retrieve(\n",
    "#     model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    "# )\n",
    "\n",
    "# train_model_uri = model_uris.retrieve(\n",
    "#     model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    "# )\n",
    "\n",
    "# # Sample training data is available in this bucket\n",
    "\n",
    "# training_dataset_s3_path = \"./predict-volcanic-eruptions-ingv-oe/train\" \n",
    "# validation_dataset_s3_path = \"./predict-volcanic-eruptions-ingv-oe/test\" \n",
    "\n",
    "\n",
    "# s3_output_location = f\"./predict-volcanic-eruptions-ingv-oe/output\"\n",
    "# pathlib.Path(\"s3_output_location\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# from sagemaker import hyperparameters\n",
    "\n",
    "# # Retrieve the default hyperparameters for training the model\n",
    "# hyperparameters = hyperparameters.retrieve_default(\n",
    "#     model_id=train_model_id, model_version=train_model_version\n",
    "# )\n",
    "\n",
    "# # [Optional] Override default hyperparameters with custom values\n",
    "# hyperparameters[\n",
    "#     \"num_boost_round\"\n",
    "# ] = \"500\"\n",
    "# print(hyperparameters)\n",
    "\n",
    "# from sagemaker.estimator import Estimator\n",
    "# from sagemaker.utils import name_from_base\n",
    "\n",
    "# training_job_name = name_from_base(f\"built-in-algo-{train_model_id}-training\")\n",
    "\n",
    "# # Create SageMaker Estimator instance\n",
    "# tabular_estimator = Estimator(\n",
    "#     role=aws_role,\n",
    "#     image_uri=train_image_uri,\n",
    "#     source_dir=train_source_uri,\n",
    "#     model_uri=train_model_uri,\n",
    "#     entry_point=\"transfer_learning.py\",\n",
    "#     instance_count=1, # for distributed training, specify an instance_count greater than 1\n",
    "#     instance_type=training_instance_type,\n",
    "#     max_run=360000,\n",
    "#     hyperparameters=hyperparameters,\n",
    "#     output_path=s3_output_location\n",
    "# )\n",
    "\n",
    "# # Launch a SageMaker Training job by passing the S3 path of the training data\n",
    "# tabular_estimator.fit(\n",
    "#     {\n",
    "#         \"train\": training_dataset_s3_path,\n",
    "#         \"validation\": validation_dataset_s3_path,\n",
    "#     }, logs=True, job_name=training_job_name\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
